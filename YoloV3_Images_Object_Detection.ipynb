{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless numpy\n",
    "!wget https://pjreddie.com/media/files/yolov3.weights -O yolov3.weights\n",
    "!wget https://github.com/pjreddie/darknet/raw/master/cfg/yolov3.cfg -O yolov3.cfg\n",
    "!wget https://github.com/pjreddie/darknet/raw/master/data/coco.names -O coco.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from google.colab.patches import cv2_imshow\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "file_name = list(uploaded.keys())[0]\n",
    "print(f\"File which is uploaded: {file_name}\")\n",
    "\n",
    "#Read the uploaded image with OpenCV\n",
    "image = cv2.imread(file_name)\n",
    "\n",
    "#Check if the image is uploaded successfully\n",
    "if image is None:\n",
    "\n",
    "  raise ValueError(\"Image didn't upload. Please check the file which is uploaded.\") #If you get that error it's probably bc of the image format is not support bt google colab so you can use the code which is i gave under of code in comment line\n",
    "else:\n",
    "  print(\"Image uploaded succesfully:\", image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That code block is show your image is valid or invalid display format\n",
    "print(f\"File name: {file_name}\")\n",
    "!ls -l\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    img_test = Image.open(file_name)\n",
    "    img_test.verify()  # verify that it is, in fact an image\n",
    "    print(\"Image is valid foramt\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Image is invalid foramt: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the image\n",
    "cv2_imshow(image) #original\n",
    "cv2.imread(file_name) #processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded with pillow\n",
    "img = Image.open(file_name)\n",
    "image = np.array(img)\n",
    "\n",
    "print(\"Image uploaded Pillow succesfully:\", image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"yolov3.weights\"\n",
    "config_path = \"yolov3.cfg\"\n",
    "names_path = \"coco.names\"\n",
    "\n",
    "with open(names_path, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Upload YOLO network\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# Processed image\n",
    "height, width, _ = image.shape\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "net.setInput(blob)\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "# Object detection\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:  #Confidence threshold\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, score_threshold=0.5, nms_threshold=0.4)\n",
    "cv2_imshow(image) #original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, score_threshold=0.5, nms_threshold=0.4)\n",
    "# Draw the objects which is detected\n",
    "if len(indices) == 0:\n",
    "    print(\"None of the object detected.\")\n",
    "else:\n",
    "    for i in indices.flatten():\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        confidence = confidences[i]\n",
    "        color = (0, 255, 0)  #Color of box is green\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(image, f\"{label} {confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "# Show the objects which is detected\n",
    "cv2_imshow(image) #processed"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
